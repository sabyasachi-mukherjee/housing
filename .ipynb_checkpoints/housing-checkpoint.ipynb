{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa5c177",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "We work with the housing data set from California (1990) and try to find a model that best describes median house values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff6c68",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4f1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f0f870c",
   "metadata": {},
   "source": [
    "Versions of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591dbaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 1.4.2\n",
      "Numpy version: 1.21.5\n",
      "Matplotlib version: 3.5.1\n",
      "Sklearn version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "print('Pandas version: %s' %pd.__version__)\n",
    "print('Numpy version: %s' %np.__version__)\n",
    "print('Matplotlib version: %s' %mpl.__version__)\n",
    "print('Sklearn version: %s' %sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27eaee4",
   "metadata": {},
   "source": [
    "We import the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ef058c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Github\\\\housing\\\\housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m housing \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGithub\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhousing\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhousing.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Github\\\\housing\\\\housing.csv'"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"D:\\Github\\housing\\housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425ff01",
   "metadata": {},
   "source": [
    "Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315544b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a570d",
   "metadata": {},
   "source": [
    "This reveals that there are 10 columns and 20, 640 rows. The column names are\n",
    "\n",
    "'longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "'total_bedrooms', 'population', 'households', 'median_income',\n",
    "'median_house_value', 'ocean_proximity'].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd925ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e870b25",
   "metadata": {},
   "source": [
    "Clearly, there are some values missing in the total_bedrooms category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec444a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins =50, figsize= (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4635ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42) #splits data int0 80-20\n",
    "#no chance of updates though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60607e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] =pd.cut(housing[\"median_income\"],\n",
    "                             bins = [0., 1.5, 3.0, 4.5, 6. , np.inf],\n",
    "                             labels = [1, 2, 3, 4, 5]) #np.inf = floating pt. rep. of infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set  = housing.loc[test_index] #We use this so that the data gets shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d10ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d82503",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy() #we just call the stratified shuffled training set housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr() #correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c60b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e917d08",
   "metadata": {},
   "source": [
    "Median house value seems to be very strongly correlated to median_income. The following scatter plot captures\n",
    "such a correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind = \"scatter\", x= \"median_income\", y = \"median_house_value\", alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f00972",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis = 1)#drops the median_house_value column\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() #and this? copies the set where? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d218de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = \"median\") \n",
    "#The missing values from data-set (here, it is total_bedrooms) are replaced by the median of that attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4fcc29",
   "metadata": {},
   "source": [
    "We drop ocean proximity, so that imputer can work on the columns with float attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185be72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c395fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65895cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputer.fit(housing_num) #fit imputer housing_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1ed83",
   "metadata": {},
   "source": [
    "These are the values that the imputer comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index) #put all this back into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3359f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.ocean_proximity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0f967",
   "metadata": {},
   "source": [
    "This reveals that there are 5 different types of ocean proximity in the table. We use the One Hot Encoder to encode\n",
    "this information into sparse matrices that capture this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84140b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat_1hot= cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot #all of this for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75e491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea385f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing_cat_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15085404",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep = housing_tr\n",
    "housing_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cc110",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep[cat_encoder.categories_[0]] = housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc58b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lin_reg = LinearRegression() #what does this do? I have seen this a couple of times\n",
    "lin_reg.fit(housing_prep, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747638cf",
   "metadata": {},
   "source": [
    "Here, we measure this model's RMSE on the whole training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfcbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = lin_reg.predict(housing_prep)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_rmse #this will turn out to be very (unacceptably) large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prep, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80aaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions1 = tree_reg.predict(housing_prep)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions1)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse) #No error! Did this model overfit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, housing_prep, housing_labels, \n",
    "                        scoring = \"neg_mean_squared_error\", cv= 10) \n",
    "tree_rmse_scores = np.sqrt(-scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ed7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prep, housing_labels, \n",
    "                        scoring = \"neg_mean_squared_error\", cv= 10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42) #why this? my code doesn't run otherwise\n",
    "forest_reg.fit(housing_prep, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions2 = forest_reg.predict(housing_prep)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions2)\n",
    "forest_rmse = np.sqrt(forest_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38aad41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
